# Bidirectional LSTM Benchmark 

## 第一步：搭建框架

```python
# Imports

# Create fully connected networks

# Set device

# Hyperparameters

# Load data

# Initialize network

# Loss and optimizer

# Train network

# Check accuracy on training & test to see how good our model

```

## 第二步：Imports

#### 1. 
```python
import torch
```
torch 是 PyTorch 的核心库，它提供了多种张量操作和自动求导功能。

#### 2.  
```python
import torch.nn as nn
```
`torch.nn` : 包含了构建神经网络的基本组件，例如各种层和损失函数。
- `nn.Module`: 所有神经网络模块的基类。
- `nn.Linear`: 全连接层。
- `nn.Conv2d`: 卷积层。
- `nn.ReLU`: 激活函数。

#### 3.  
```python
import torch.optim as optim
```

`torch.optim` 包含了各种优化算法，用于更新神经网络的参数以最小化损失函数。

- `optim.SGD`: 随机梯度下降优化器。
- `optim.Adam`: Adam 优化器。

#### 4.  
```python
import torch.nn.functional as F
```
`torch.nn.functional` 提供了函数式的接口来执行神经网络的各种操作和计算，例如激活函数、卷积操作等。
- `F.relu`: ReLU 激活函数。
- `F.softmax`: Softmax 函数。

#### 5.  
```python
from torch.utils.data import DataLoader
```

`DataLoader` 是 PyTorch 提供的数据加载工具，用于将数据集加载到内存中并批量化处理。

- `DataLoader`: 数据加载器，负责打乱数据、分批次加载。

#### 6.  
```python
import torchvision.datasets as datasets
```

`torchvision.datasets` 包含了许多常用的公共数据集，可以直接用于训练和测试模型。
- (Create a binibatch to test on)
- `datasets.MNIST`: MNIST 手写数字数据集。
- `datasets.CIFAR10`: CIFAR-10 图像数据集。

#### 7.  
```python
import torchvision.transforms as transforms
```
`torchvision.transforms` 提供了一些常用的数据预处理和增强操作。
- `transforms.ToTensor()`: 将图像转换为张量。
- `transforms.Normalize(mean, std)`: 归一化操作。


#### complete code
```python
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import DataLoader
import torchvision.datasets as datasets
import torchvision.transforms as transforms
```

## 第三步：Create fully connected networks

```python
class NN(nn.Module):
    def __init__(self, input_size, num_classes):
        super(NN, self).__init__()
        self.fc1 = nn.Linear(input_size, 50)
        self.fc2 = nn.Linear(50, num_classes)

    def forward(self, x):
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x
```

设置一个断点来检查模型的大小是否正确

```python
# Create a sample network to verify
Model = NN(784, 10)
x = torch.randn(64, 784)
print(Model(x).shape)
```

## 第四步：Create a Bidirectional LSTM

```python
class BRNN(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, num_classes):

        # Initialize the parent class
        super(BRNN, self).__init__()

        # Set hidden size and number of layers
        self.hidden_size = hidden_size
        self.num_layers = num_layers

        # Define an LSTM layer
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)

        # Define a fully connected layer
        # hidden_size*2 because the LSTM is bidirectional, so it concatenates the outputs of two LSTMs
        # num_classes: Number of output classes
        self.fc = nn.Linear(hidden_size*2, num_classes)

    def forward(self, x):

        # Initialize hidden state and cell state with zeros
        # num_layers*2 because the LSTM is bidirectional
        h0 = torch.zeros(self.num_layers*2, x.size(0),self.hidden_size).to(device)
        c0 = torch.zeros(self.num_layers*2, x.size(0),self.hidden_size).to(device)

        # Forward propagate the LSTM
        # out: tensor of shape (batch_size, seq_length, hidden_size*2)
        out, _ = self.lstm(x, (h0, c0))

        # out is reshaped to collapse the sequence dimension, resulting in a 2D tensor of shape
        # out = out.reshape(out.shape[0], -1)
        # out = self.fc(out)

        # Use the output of the last time step for classification
        # out[:, -1, :] is the last time step's output for each sequence in the batch
        # 在前向传播过程中，LSTM 的输出 out 是一个三维张量，形状是 (batch_size, seq_length, hidden_size*2)。
        # batch_size 是每次输入的样本数量。
        # seq_length 是每个样本的时间步数（即序列长度）。
        # hidden_size*2 是每个时间步的特征维度，因为 LSTM 是双向的，所以有两倍的隐藏层大小。
        #
        # Todo: 为什么是要最后一时间步的信息？
        # 在使用双向 LSTM 时，模型会同时处理序列的正向和反向信息。
        # 对于每个时间步，正向和反向 LSTM 的输出会被合并
        # 最终得到的输出向量包含了序列的完整上下文。
        # 选择最后一个时间步的信息，就是选择了这一融合后的信息的最终表示。
        out = self.fc(out[:, -1, :])
        return out
```
## 第五步：Set device

```python
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
```

## 第六步：Hyperparameters

在 RNN / LTSM 里参数如下：
```python
input_size = 28
sequence_length = 28
num_layers = 2

hidden_layer = 256
num_classes = 10

learning_rate = 0.001
batch_size = 64
num_epochs = 2
```

在 NN / CNN 里参数如下:
```python
input_size = 784
num_classes = 10
learning_rate = 0.01
batch_size = 64
num_epochs = 1
```

## 第七步：Load data

```python
# 加载训练数据集并将图像转换为张量
train_dataset = datasets.MNIST(root='dataset/',train=True, transform=transforms.ToTensor(), download=True)
# 创建训练数据加载器，每个批次大小为 batch_size，并在每个 epoch 开始前打乱数据
train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)
# 加载测试数据集并将图像转换为张量
test_dataset = datasets.MNIST(root='dataset/', train=False, transform=transforms.ToTensor(), download=True)
# 创建测试数据加载器，每个批次大小为 batch_size，并在每个 epoch 开始前打乱数据
test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)
```

## 第八步：Initialize network

- 在 Bidirectional LSTM 里面是
  
```python
model = BRNN(input_size, hidden_layer, num_layers, num_classes).to(device)
```

- 在 RNN 里面是
  
```python
model = RNN(input_size, hidden_layer, num_layers, num_classes).to(device)
```

- 在 CNN 里面是
  
```python
model = CNN().to(device)
```

- 在 NN 里面是
  
```python
model = NN(input_size=input_size, num_classes=num_classes).to(device)
```

## 第九步：Loss and optimizer

```python
# criterion 是损失函数，用于计算模型输出与真实标签之间的误差。
# nn.CrossEntropyLoss()：这是交叉熵损失函数，通常用于多分类问题。
# 它将模型的输出（未归一化的得分）和目标标签作为输入，并计算损失值。
# 这个损失函数会自动应用 softmax 激活函数，因此不需要在输出层手动添加 softmax。
criterion = nn.CrossEntropyLoss()

# optimizer 是优化器，用于更新模型的参数，以最小化损失函数的值。
# optim.Adam：这是 Adam 优化器，一种常用的优化算法，结合了动量和自适应学习率调整的优点。
# model.parameters()：传递模型的参数给优化器，以便它可以更新这些参数。
# lr=learning_rate：设置学习率，决定每次更新模型参数时步长的大小。
optimizer = optim.Adam(model.parameters(), lr=learning_rate)
```

## 第十步：Train network

#### 请注意，在 CNN / RNN 里面不需要数据重塑。故而，

```python
        # Get to correct shape
        # 训练数据时，你将数据重塑为 (batch_size, -1)
        # 但这是为全连接网络设计的，卷积神经网络不需要这个步骤。
        # data = data.reshape(data.shape[0],-1)
```

#### 请注意，在 RNN / LSTM 移除维度为 1 的通道维度

```python
            data = data.to(device=device).squeeze(1)
````

这里很重要为什么要 .squeeze(1) ？？？

```python
            # 因为 MNIST 数据集的图像原本是 (N, 1, 28, 28) 形状的 4D 张量
            # 而 LSTM 期望的输入形状是 (batch_size, sequence_length, input_size)
            # 即 3D 张量 (N, 28, 28)
            # 因此，需要移除维度为 1 的通道维度，以便将数据传递给 LSTM。
            # 具体来说，squeeze(1) 作用是移除第一个维度大小为 1 的维度。
            #
            # Todo: 示例说明
            #
            # 假设我们从 MNIST 数据集中加载一个批次的数据，其形状为 (64, 1, 28, 28)，其中：
            #
            # 64 是批次大小（batch size）
            # 1 是通道数（channel），因为 MNIST 是灰度图像
            # 28 是图像的高度（height）
            # 28 是图像的宽度（width）
            #
            # 但是，LSTM 期望输入形状为 (batch_size, sequence_length, input_size)
            # 对于 MNIST 数据集而言，这里：
            # batch_size 仍然是 64
            # sequence_length 是 28（高度）
            # input_size 是 28（宽度）
            # 因此，需要将形状从 (64, 1, 28, 28) 转换为 (64, 28, 28)，通过 squeeze(1) 移除大小为 1 的维度。
            # 通过这种方式，数据就变成了 LSTM 所期望的形状，可以传递给 LSTM 进行处理。
```

#### complete code

```python
for epoch in range(num_epochs):
    for batch_index, (data,target) in enumerate (train_loader):
        # Get data to cuda if possible
        data = data.to(device=device).squeeze(1)
        target = target.to(device=device)

        # Get to correct shape
        # 训练数据时，你将数据重塑为 (batch_size, -1)
        # 但这是为全连接网络设计的，卷积神经网络不需要这个步骤。
        # data = data.reshape(data.shape[0],-1)

        # forward
        scores = model(data)
        loss = criterion(scores, target)

        # backward
        optimizer.zero_grad()
        loss.backward()

        # gradient descent on adam step
        # 参数更新
        optimizer.step()
```

## 第十一步：Check accuracy on training & test to see how good our model


#### 请注意，在 CNN / RNN 里面不需要数据重塑。故而，

```python
        # Get to correct shape
        # 训练数据时，你将数据重塑为 (batch_size, -1)
        # 但这是为全连接网络设计的，卷积神经网络不需要这个步骤。
        # data = data.reshape(data.shape[0],-1)
```

#### 请注意，在 RNN / LSTM 移除维度为 1 的通道维度

```python
            data = data.to(device=device).squeeze(1)
````

#### complete code
```python
def check_accuracy(loader, model):

    if loader.dataset == train_dataset:
        print("Checking LSTM accuracy on training set")
    else:
        print("Checking LSTM accuracy on test set")

    num_correct = 0
    num_samples = 0
    # model.eval()：将模型设置为评估模式，禁用 dropout 和 batch normalization。
    model.eval()

    # torch.no_grad()：在这个上下文中禁用梯度计算，以节省内存和计算资源。
    with torch.no_grad():
        for data, target in loader:
            data = data.to(device=device).squeeze(1)
            target = target.to(device=device)

            output = model(data)
            _,predictions = output.max(dim=1)

            num_correct += (predictions == target).sum()
            num_samples += predictions.size(0)

        print(f'Got {num_correct} / {num_samples} with LSTM accuracy {num_correct / num_samples * 100:.2f}')

    model.train()

check_accuracy(train_loader, model)
check_accuracy(test_loader, model)
```

## PyToch Output

```python
Checking LSTM accuracy on training set
Got 58823 / 60000 with LSTM accuracy 98.04

Checking LSTM accuracy on test set
Got 9787 / 10000 with LSTM accuracy 97.87
```

## Complete Code

```python
# Bidirectional LSTM

# Imports ( 7 imports and 8 lines )
import torch
import torchvision
# Todo: All neural network modules. nn.Linear, nn.Conv2d, BatchNorm, Loss functions
import torch.nn as nn
# Todo: For all Optimization algorithms, SGD, Adam, etc.
import torch.optim as optim
# Todo: All functions that don't have any parameters
import torch.nn.functional as F
# Todo: Gives easier dataset management and creates mini batches
from torch.utils.data import DataLoader
# Todo: Has standard datasets we can import in a nice way
import torchvision.datasets as datasets
# Todo: Transformations we can perform on our dataset
import torchvision.transforms as transforms

# Set device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Hyperparameters
input_size = 28
sequence_length = 28
num_layers = 2

hidden_size = 256
num_classes = 10

learning_rate = 0.001
batch_size = 64
num_epochs = 2

# Create a bidirectional LSTM
class BRNN(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, num_classes):

        # Initialize the parent class
        super(BRNN, self).__init__()

        # Set hidden size and number of layers
        self.hidden_size = hidden_size
        self.num_layers = num_layers

        # Define an LSTM layer
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)

        # Define a fully connected layer
        # hidden_size*2 because the LSTM is bidirectional, so it concatenates the outputs of two LSTMs
        # num_classes: Number of output classes
        self.fc = nn.Linear(hidden_size*2, num_classes)

    def forward(self, x):

        # Initialize hidden state and cell state with zeros
        # num_layers*2 because the LSTM is bidirectional
        h0 = torch.zeros(self.num_layers*2, x.size(0),self.hidden_size).to(device)
        c0 = torch.zeros(self.num_layers*2, x.size(0),self.hidden_size).to(device)

        # Forward propagate the LSTM
        # out: tensor of shape (batch_size, seq_length, hidden_size*2)
        out, _ = self.lstm(x, (h0, c0))

        # out is reshaped to collapse the sequence dimension, resulting in a 2D tensor of shape
        # out = out.reshape(out.shape[0], -1)
        # out = self.fc(out)

        # Use the output of the last time step for classification
        # out[:, -1, :] is the last time step's output for each sequence in the batch
        # 在前向传播过程中，LSTM 的输出 out 是一个三维张量，形状是 (batch_size, seq_length, hidden_size*2)。
        # batch_size 是每次输入的样本数量。
        # seq_length 是每个样本的时间步数（即序列长度）。
        # hidden_size*2 是每个时间步的特征维度，因为 LSTM 是双向的，所以有两倍的隐藏层大小。
        #
        # Todo: 为什么是要最后一时间步的信息？
        # 在使用双向 LSTM 时，模型会同时处理序列的正向和反向信息。
        # 对于每个时间步，正向和反向 LSTM 的输出会被合并
        # 最终得到的输出向量包含了序列的完整上下文。
        # 选择最后一个时间步的信息，就是选择了这一融合后的信息的最终表示。
        out = self.fc(out[:, -1, :])
        return out

# Load data
train_dataset = datasets.MNIST(root='dataset/', train=True, transform=transforms.ToTensor(), download=True)
train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)
test_dataset = datasets.MNIST(root='dataset/', train=False, transform=transforms.ToTensor(), download=True)
test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)

# Initialize network
model = BRNN(input_size, hidden_size, num_layers, num_classes).to(device)

# Loss and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr = learning_rate)

# Train network
for epoch in range(num_epochs):
    for batch_idx, (data, target) in enumerate(train_loader):
        # Get data to cuda if possible
        data = data.to(device=device).squeeze(1)
        target = target.to(device=device)

        # Get to correct shape
        # 训练数据时，你将数据重塑为 (batch_size, -1)
        # 但这是为全连接网络设计的，卷积神经网络不需要这个步骤。
        # data = data.reshape(data.shape[0],-1)

        # Forward
        output = model(data)
        loss = criterion(output, target)

        # Backward
        optimizer.zero_grad()
        loss.backward()

        # Gradient descent or Adam step
        optimizer.step()

# Check accuracy on training & test to see how good our model

def check_accuracy(loader, model):

    if loader.dataset == train_dataset:
        print("Checking LSTM accuracy on training set")
    else:
        print("Checking LSTM accuracy on test set")

    num_correct = 0
    num_samples = 0
    model.eval()

    with torch.no_grad():
        for data, target in loader:

            # 这里很重要为什么要 .squeeze(1) ？？？
            # 因为 MNIST 数据集的图像原本是 (N, 1, 28, 28) 形状的 4D 张量
            # 而 LSTM 期望的输入形状是 (batch_size, sequence_length, input_size)
            # 即 3D 张量 (N, 28, 28)
            # 因此，需要移除维度为 1 的通道维度，以便将数据传递给 LSTM。
            # 具体来说，squeeze(1) 作用是移除第一个维度大小为 1 的维度。
            #
            # Todo: 示例说明
            #
            # 假设我们从 MNIST 数据集中加载一个批次的数据，其形状为 (64, 1, 28, 28)，其中：
            #
            # 64 是批次大小（batch size）
            # 1 是通道数（channel），因为 MNIST 是灰度图像
            # 28 是图像的高度（height）
            # 28 是图像的宽度（width）
            #
            # 但是，LSTM 期望输入形状为 (batch_size, sequence_length, input_size)
            # 对于 MNIST 数据集而言，这里：
            # batch_size 仍然是 64
            # sequence_length 是 28（高度）
            # input_size 是 28（宽度）
            # 因此，需要将形状从 (64, 1, 28, 28) 转换为 (64, 28, 28)，通过 squeeze(1) 移除大小为 1 的维度。
            # 通过这种方式，数据就变成了 LSTM 所期望的形状，可以传递给 LSTM 进行处理。

            data = data.to(device=device).squeeze(1)
            target = target.to(device=device)

            # Get to correct shape
            # 训练数据时，你将数据重塑为 (batch_size, -1)
            # 但这是为全连接网络设计的，卷积神经网络不需要这个步骤。
            # data = data.reshape(data.shape[0],-1)

            output = model(data)
            _,predictions = output.max(dim=1)

            num_correct += (predictions == target).sum()
            num_samples += predictions.size(0)

        print(f'Got {num_correct} / {num_samples} with LTSM accuracy {num_correct / num_samples * 100:.2f}')

    model.train()

check_accuracy(train_loader, model)
check_accuracy(test_loader, model)
```

