# 大模型训练相关面试问答 11-25

------
11. 关于微调的方法
12. 训练模型的基座、数据和微调方法选择
13. 如何解决大语言模型的幻觉问题，RLHF是否可行
14. 国内做基座模型工作的前景
15. 为什么模型越大貌似更具AGI的能力
16. Transformer网络结构及与LSTM的区别
17. Transformer中使用的正则化方法
18. ChatGPT训练中的奖励模型是否有更新
19. ChatGPT强化学习训练阶段的改进空间
20. 直接用训练reward model的数据精调模型而不使用强化学习是否可行
21. BERT与GPT网络结构的细节及其差异
22. Reward model不准时的应对方法
23. Reward模型训练时有无类似过拟合的现象
24. 是否需要对reward model单独测试效果
25. 使用RLHF的可行性分析
-----
